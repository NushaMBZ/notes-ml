---
aliases:
  - Memory Coalescing
date: 2025-04-18
links:
  - "[[1744799422|Global Memory]]"
  - "[[1744799324|Warp]]"
  - "[[1744952920|Bank Conflicts]]"
---
Memory coalescing is a GPU memory access optimization technique that allows multiple threads in a warp to combine their memory accesses into a smaller number of DRAM transactions. 

> [!Example]
> In massively parallel processors, such as NVIDIA GPUs, each warp contains 32 threads. If each thread accesses global memory in an unaligned or scattered way, the GPU must issue separate memory transactions for each access, leading to high latency and reduced bandwidth utilization. 
> 

However, if the threads access memory in a sequential or aligned pattern (e.g., thread 0 accesses address A, thread 1 accesses A+4, etc.), the hardware coalesces these accesses into one or a few wide memory transactions. Coalescing significantly improves throughput and is most effective when memory addresses fall into the same memory segment or cache line. The efficiency of memory coalescing is closely related to how data is laid out in memory and how threads are assigned to process that data.